{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Here, we will demonstrate the use of generalized additive models and trees. For this work, we will be reusing our Lab 2 dataset. I will reiterate that cross-validation must be done to have any confidence in your ML models. At the very least, a proper training/test split should be done.\n",
    "\n",
    "As we move towards the end of this course, we are going to be working with much more sophisticated tools in the scikit-learn package. Specifically, one of the things we will use extensively is [sklearn.model_selection.GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV). This class allows us to scan a set of parameter values for a model and return the CV results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from pymatgen.core import Element, Composition\n",
    "\n",
    "rcparams = {'legend.fontsize': 20,\n",
    "            'figure.figsize': (12, 8),\n",
    "            'axes.labelsize': 24,\n",
    "            'axes.titlesize': 28,\n",
    "            'xtick.labelsize':20,\n",
    "            'ytick.labelsize': 20}\n",
    "sns.set(rc=rcparams)\n",
    "mpl.rcParams.update(rcparams)\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor, AdaBoostClassifier, \\\n",
    "    GradientBoostingClassifier, GradientBoostingRegressor, \\\n",
    "    RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.tree import export_text, export_graphviz\n",
    "\n",
    "from statsmodels.gam.generalized_additive_model import GLMGam\n",
    "from statsmodels.gam.api import BSplines\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by default pandas will recognize NaN (sodium nitride) as nan (not a number)\n",
    "# to turn off this behavior, we use na_filter=False\n",
    "data_url = \"https://raw.githubusercontent.com/materialsvirtuallab/nano281/master/labs/lab2/data.csv\"\n",
    "data = pd.read_csv(data_url, index_col=0, na_filter=False)\n",
    "\n",
    "# Let's create a column of Composition objects using pymatgen.\n",
    "data[\"composition\"] = [Composition(f) for f in data[\"formula\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we load the elemental data. Unlike lab2, we are simply going to disregard all elemental features that contain NaN. While imputing the mean value is a commonly used data science technique, it really does not work well for materials science problems. We will also use a smaller set of properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "el_data_url = \"https://raw.githubusercontent.com/materialsvirtuallab/nano281/master/labs/lab2/element_properties.csv\"\n",
    "el_data = pd.read_csv(el_data_url, index_col=0)\n",
    "el_data = el_data[['AtomicRadius', 'AtomicWeight', 'Column', 'Electronegativity', 'Row']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we will compute the mean, min, and max for every elemental feature. For mean, we are weighting it by composition. As before, we drop all data points that contain NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124342, 21)\n"
     ]
    }
   ],
   "source": [
    "props = collections.defaultdict(list)\n",
    "\n",
    "for comp in data[\"composition\"]:\n",
    "    for c in el_data.columns:\n",
    "        vals = [el_data[c][el.symbol] for el, amt in comp.items()]\n",
    "        comp_vals = [el_data[c][el.symbol] * amt for el, amt in comp.items()]\n",
    "        props[\"%sMean\" % c].append(sum(comp_vals)/ comp.num_atoms)\n",
    "        props[\"%sMin\" % c].append(min(vals))\n",
    "        props[\"%sMax\" % c].append(max(vals))\n",
    "data = data.assign(**props)\n",
    "data = data.dropna()\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are left with around 106k data points, Still more than enough for our purposes. Let's create our features and targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in data.columns if c.endswith(\"Mean\") or c.endswith(\"Min\") or c.endswith(\"Max\")]\n",
    "x = data[features]\n",
    "y_class = [0 if bg < 1e-4 else 1 for bg in data[\"band_gap\"]]\n",
    "y_reg = data[\"band_gap\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we proceed further, let us write up some reusable methods to standardize the analysis of different ML models. Copy and pasting code is fine for earlier demos to reiterate the API of scikit-learn, but it is very bad programming practice. By this stage of the course, we want to do things better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grid_search_results(gs, ylim=None):\n",
    "    \"\"\"\n",
    "    Plots the results of GridSearchCV.\n",
    "    \n",
    "    Args:\n",
    "        gs: A GridSearchCV object.\n",
    "        ylim: Optional setting for y limits.\n",
    "    \"\"\"\n",
    "    results = pd.DataFrame(gs.cv_results_)\n",
    "    for c in results.columns:\n",
    "        # Note that here we are working with just variations in one parameter.\n",
    "        # So we can automatically find the name of that parameter.\n",
    "        if c.startswith(\"param_\"):\n",
    "            x = c\n",
    "            break\n",
    "    fig, ax = plt.subplots(figsize=(16, 8))    \n",
    "    ax = sns.lineplot(x=x, y=\"mean_train_score\", data=results)\n",
    "    ax = sns.scatterplot(x=x, y=\"mean_train_score\", data=results, marker='x')\n",
    "    ax = sns.lineplot(x=x, y=\"mean_test_score\", data=results)\n",
    "    ax = sns.scatterplot(x=x, y=\"mean_test_score\", data=results, marker='o')\n",
    "    plt.xlabel(x)\n",
    "    if ylim:\n",
    "        plt.ylim(ylim)\n",
    "    ax.legend([\"Train\", \"Test\"], loc=2);\n",
    "    \n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized Additive Models\n",
    "\n",
    "Since sklearn does not have generalized additive models, we will use statsmodels for fitting such models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAM model is difficult to train, here we use a very small train data size \n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y_class, test_size=0.9, random_state=42)\n",
    "\n",
    "# smoother over the 15 variables, with each variable using 6 basis function (the df parameter)\n",
    "# and degree of 4 (the degree parameter) splines. \n",
    "bs = BSplines(x_train, df=[6] * 15, degree=[4] * 15 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training data frame, which contains the features and the target, i.e., is_metal\n",
    "combined_xy = x_train.copy()\n",
    "combined_xy = combined_xy.assign(**{'is_metal': y_train})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that the target `is_metal` is either 0 or 1, which follows a Berloulli distribution. The Berloulli distribution can be seen as a special case of Binomial distribution with total number of trial of 1. \n",
    "\n",
    "Therefore, we model the target $Y$ (i.e., `is_metal`) as a Binomial distribution. \n",
    "\n",
    "$g(E(Y)) = \\beta_0 + \\sum_i^Kf_i(x_i)$\n",
    "\n",
    "$\\beta_0$ is the intercept, $i$ means the i-th variable, and $f_i(x_i)$ is modeled as a smooth function. In our case, the smooth function is B-spline defined earlier. \n",
    "\n",
    "In order to reproduce the correct distribution of $Y$, we set the link function $g$ to a logit function. \n",
    "\n",
    "$g(x) = \\log\\frac{x}{1-x}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Calling Family(..) with a link class is not allowed. Use an instance of a link class instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Gaussian family with Logit link function\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m binomial \u001b[38;5;241m=\u001b[39m \u001b[43msm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfamilies\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43msm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfamilies\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m gam_bs \u001b[38;5;241m=\u001b[39m GLMGam\u001b[38;5;241m.\u001b[39mfrom_formula(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_metal ~ 1\u001b[39m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m=\u001b[39mcombined_xy, \n\u001b[1;32m      5\u001b[0m                              smoother\u001b[38;5;241m=\u001b[39mbs, family\u001b[38;5;241m=\u001b[39mbinomial)\n",
      "File \u001b[0;32m~/miniconda3/envs/mavrl/lib/python3.9/site-packages/statsmodels/genmod/families/family.py:893\u001b[0m, in \u001b[0;36mBinomial.__init__\u001b[0;34m(self, link)\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    891\u001b[0m \u001b[38;5;66;03m# overwritten by initialize if needed but always used to initialize\u001b[39;00m\n\u001b[1;32m    892\u001b[0m \u001b[38;5;66;03m# variance since endog is assumed/forced to be (0,1)\u001b[39;00m\n\u001b[0;32m--> 893\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mBinomial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlink\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlink\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mvariance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mV\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mavrl/lib/python3.9/site-packages/statsmodels/genmod/families/family.py:83\u001b[0m, in \u001b[0;36mFamily.__init__\u001b[0;34m(self, link, variance)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misclass(link):\n\u001b[1;32m     79\u001b[0m     warnmssg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalling Family(..) with a link class is not allowed. Use an \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstance of a link class instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     82\u001b[0m     )\n\u001b[0;32m---> 83\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(warnmssg)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlink \u001b[38;5;241m=\u001b[39m link\n",
      "\u001b[0;31mTypeError\u001b[0m: Calling Family(..) with a link class is not allowed. Use an instance of a link class instead."
     ]
    }
   ],
   "source": [
    "# Gaussian family with Logit link function\n",
    "\n",
    "binomial = sm.families.Binomial(sm.families.links.logit)\n",
    "gam_bs = GLMGam.from_formula('is_metal ~ 1', data=combined_xy, \n",
    "                             smoother=bs, family=binomial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The formula means that other than the generalized additive models using B-Splines, there is only an extra intercept term (1 in \"is_metal ~ 1\").\n",
    "\n",
    "We can of course include other linear relationship here. For example, if we believe there is an extra linear dependence on AtomicRadiusMean, we should write the formula as \n",
    "\n",
    "\"is_metal ~ AtomicRadiusMean + 1\"\n",
    "\n",
    "Note that the generalized additive models are added to the relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time res_bs = gam_bs.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = []\n",
    "y_test_valid = []\n",
    "\n",
    "# some test x is outside the training x bounds, which will cause errors, \n",
    "# we use try... except to ignore this error\n",
    "for x_test_temp, y_test_temp in zip(x_test.values, y_test):\n",
    "    try:\n",
    "        transformed = bs.transform(x_test_temp.reshape((1, -1)))\n",
    "        transformed = np.concatenate([np.array([[1]]), transformed], axis=1)  # add intercept\n",
    "        y_pred_test.append(gam_bs.predict(res_bs.params, transformed).item())\n",
    "        y_test_valid.append(y_test_temp)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print((f\"The prediction accuracy on {len(y_test_valid)} test data is \"\n",
    "       f\"{accuracy_score(np.array(y_pred_test)>=0.5, y_test_valid):.3f}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree classifier\n",
    "\n",
    "Here, we will construct a decision tree classifier. Let us explore how the classficication accuracy changes with the tree depth. We will use an extremely powerful tool in the scikit-learn toolkit called GridSearchCV, which automatically varies a parameter across a set of values and returns the CV results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(\n",
    "    DecisionTreeClassifier(random_state=0),\n",
    "    param_grid={\"max_depth\": list(range(1, 20))},\n",
    "    return_train_score=True,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=kfold\n",
    ")\n",
    "gs.fit(x, y_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid_search_results(gs)\n",
    "plt.ylabel(\"accuracy\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the test and training accuracy diverges after a tree depth of 8 or so, and the test accuracy plateaus after a tree depth of 15 or so. A relatively good accuracy of around 80% can be achieved. Let's visualize the tree structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y_class, test_size=0.2)\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(criterion=\"entropy\", random_state=0, max_depth=8)\n",
    "decision_tree.fit(x_train, y_train)\n",
    "\n",
    "# We can export this to a graphviz dot file, which can be used to generate a nice plot.\n",
    "export_graphviz(decision_tree, out_file=\"metal_insulator_tree.dot\", feature_names=list(x.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what happens when we change the pruning parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state=0, max_depth=8)\n",
    "gs = GridSearchCV(\n",
    "    decision_tree,\n",
    "    param_grid={\"ccp_alpha\": [1e-4, 1e-3, 1e-2]},\n",
    "    return_train_score=True,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=kfold\n",
    ")\n",
    "gs.fit(x, y_class)\n",
    "plot_grid_search_results(gs)\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xscale('log');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we increase $\\alpha$, we decrease the accuracy, but the tree depth decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now visualize a smaller tree to see how decisions are made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier(criterion=\"entropy\", random_state=0, max_depth=3)\n",
    "decision_tree.fit(x_train, y_train)\n",
    "r = export_text(decision_tree, feature_names=list(x.columns))\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance\n",
    "\n",
    "A very useful of decision trees is that we can visualize the feature importance quite easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state=0, max_depth=8)\n",
    "decision_tree.fit(x_train, y_train)\n",
    "plt.subplots(figsize=(16, 16))\n",
    "sns.barplot(decision_tree.feature_importances_, list(x.columns), orient='h')\n",
    "plt.xlabel(\"Feature importance\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receiver Operating Characteristic Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(16, 16))\n",
    "for d in [4, 8, 16, 32]:\n",
    "    decision_tree = DecisionTreeClassifier(random_state=0, max_depth=d)\n",
    "    decision_tree = decision_tree.fit(x_train, y_train)\n",
    "    train_accuracy = decision_tree.score(x_train, y_train)\n",
    "    test_accuracy = decision_tree.score(x_test, y_test)\n",
    "\n",
    "    y_pred = decision_tree.predict_proba(x_test)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "    a = roc_auc_score(y_test, y_pred)\n",
    "    plt.plot(fpr, tpr, 'o-', label='d = %d, AUC = %.3f' % (d, a))\n",
    "\n",
    "plt.plot([0, 0, 1], [0, 1, 1], 'k-', label=\"Ideal\")\n",
    "plt.plot([0, 1], [0, 1], 'k-.', label=\"Random guess\")\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regressor\n",
    "\n",
    "Instead of just classifying metals and insulators, let us now use the decision tree for regression instead. Here, we will use MSE instead of classification accuracy as the criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeRegressor(random_state=0)\n",
    "gs = GridSearchCV(\n",
    "    decision_tree,\n",
    "    param_grid={\"max_depth\": range(1, 20)},\n",
    "    return_train_score=True,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    cv=kfold\n",
    ")\n",
    "gs.fit(x, y_reg)\n",
    "plot_grid_search_results(gs)\n",
    "plt.ylabel(\"-MSE\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that an optimal tree depth of around 15 or so in terms of minimizing MSE. We can achieve a MSE of slightly more than 1 eV. Not great, but reasonable for such a simple model. Let us now explore how alpha affects the tree depth and the MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeRegressor(criterion=\"mse\", random_state=0, max_depth=15)\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    decision_tree,\n",
    "    param_grid={\"ccp_alpha\": np.logspace(-4, -1, 10)},\n",
    "    return_train_score=True,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    cv=kfold\n",
    ")\n",
    "gs.fit(x, y_reg)\n",
    "plot_grid_search_results(gs)\n",
    "plt.ylabel(\"- MSE\")\n",
    "plt.xscale('log');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we increase $\\alpha$, we get a simpler (shallower) tree, but the MSE increases. However, the training and test error converges and we get less overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a relatively small tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y_reg, test_size=0.2)\n",
    "\n",
    "decision_tree = DecisionTreeRegressor(criterion=\"mse\", random_state=0, max_depth=15, ccp_alpha=0.01)\n",
    "decision_tree.fit(x_train, y_train)\n",
    "y_pred = decision_tree.predict(x_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r = export_text(decision_tree, feature_names=list(x.columns))\n",
    "print(\"MSE = %.3f\" % (mse))\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning\n",
    "\n",
    "Here, we are going to look at some ensemble learning approaches to improve the predictions of decision trees for both classification and regression. To demonstrate the impact more clearly, we will use relatively shallow trees of `max_depth=8` for classification and `max_depth=15` for regression throughout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_class = 3\n",
    "max_depth_reg = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AdaBoostClassifier(DecisionTreeClassifier(random_state=0, max_depth=max_depth_class))\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    model,\n",
    "    param_grid={\"n_estimators\": range(10, 100, 20)},\n",
    "    return_train_score=True,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=kfold\n",
    ")\n",
    "gs.fit(x, y_class)\n",
    "plot_grid_search_results(gs)\n",
    "plt.ylabel(\"accuracy\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that even with a small tree, boosting allows us to achieve higher classification accuracies. There is some evidence of overfitting, as can be seen from the divergence of the training and test accuracies. We can of course play around with the tree depth as well as the learning rate to improve the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For regression, we will use a decision tree with a max depth of 15 and a lower learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AdaBoostRegressor(DecisionTreeRegressor(random_state=0, max_depth=max_depth_reg), \n",
    "                          learning_rate=0.1)\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    model,\n",
    "    param_grid={\"n_estimators\": [2, 4, 8, 16, 32, 64]},\n",
    "    return_train_score=True,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    cv=kfold\n",
    ")\n",
    "gs.fit(x, y_reg)\n",
    "plot_grid_search_results(gs)\n",
    "plt.ylabel(\"- MSE\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we can get to a substantially lower test MSE of 0.85 eV or so with boosting, albeit with some evidence of over-fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier(random_state=0, max_depth=max_depth_class)\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    model,\n",
    "    param_grid={\"n_estimators\": range(10, 800, 100)},\n",
    "    return_train_score=True,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=kfold,\n",
    "    n_jobs=4\n",
    ")\n",
    "gs.fit(x, y_class)\n",
    "plot_grid_search_results(gs)\n",
    "plt.ylabel(\"accuracy\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingRegressor(random_state=0, max_depth=max_depth_reg)\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    model,\n",
    "    param_grid={\"n_estimators\": range(10, 100, 20)},\n",
    "    return_train_score=True,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    cv=kfold,\n",
    "    n_jobs=4\n",
    ")\n",
    "gs.fit(x, y_reg)\n",
    "plot_grid_search_results(gs)\n",
    "plt.ylabel(\"-MSE\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests\n",
    "\n",
    "We will now lookn at random forest models for performing the same classificaiton and regression tasks. For classification, we will first use the same maximum tree depth as before of 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=0, max_depth=max_depth_class)\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    model,\n",
    "    param_grid={\"n_estimators\": range(20, 120, 20)},\n",
    "    return_train_score=True,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=kfold,\n",
    "    n_jobs=4\n",
    ")\n",
    "gs.fit(x, y_class)\n",
    "plot_grid_search_results(gs)\n",
    "plt.ylabel(\"accuracy\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that with a maximum depth of 3, there is very little overfitting, but the performance is somewhat lower that what we have achieved with gradient boosting.\n",
    "\n",
    "Let us now remove all variables and let the default implementation try to find the optimal random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=0)\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    model,\n",
    "    param_grid={\"n_estimators\": range(1, 40, 4)},\n",
    "    return_train_score=True,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=kfold,\n",
    "    n_jobs=4\n",
    ")\n",
    "gs.fit(x, y_class)\n",
    "plot_grid_search_results(gs)\n",
    "plt.ylabel(\"accuracy\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the performance has substantially improved for both training and test data, but there is evidence of significant overfitting!\n",
    "\n",
    "We can gain some insights into how the random forest is getting this performance by looking at the feature importances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=0, n_estimators=20)\n",
    "model.fit(x, y_class)\n",
    "plt.subplots(figsize=(16, 16))\n",
    "sns.barplot(model.feature_importances_, list(x.columns), orient='h')\n",
    "plt.xlabel(\"Feature importance\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now look at the random forest for the regression task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(random_state=0, max_depth=max_depth_reg)\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    model,\n",
    "    param_grid={\"n_estimators\": range(1, 20, 2)},\n",
    "    return_train_score=True,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    cv=kfold,\n",
    "    n_jobs=8\n",
    ")\n",
    "gs.fit(x, y_reg)\n",
    "plot_grid_search_results(gs)\n",
    "plt.ylabel(\"-MSE\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the same max depth, we see that the performance has substantially improved. A test MSE of < 1eV is now possible but again, we see quite a bit of overfitting. Let's try to gain some insight into the base decision tree being used with 10 estimators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While you can try to further tweak he model by setting parameters like `min_samples leaf`, a simpler approach is to just let the algorithm automatically prune the tree by setting the $\\alpha$ parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(random_state=0, max_depth=15, n_estimators=10)\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    model,\n",
    "    param_grid={\"ccp_alpha\": [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]},\n",
    "    return_train_score=True,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    cv=kfold,\n",
    "    n_jobs=8\n",
    ")\n",
    "gs.fit(x, y_reg)\n",
    "plot_grid_search_results(gs)\n",
    "plt.ylabel(\"-MSE\");\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite clearly, there is a tradeoff between tree complexity, MSE and overfitting. At high $\\alpha > 1e-3$, there is minimal overfitting but the best we can do is an MSE of around 1.2 eV or more. The less the overfitting, the more confidence we have about the model being generalizable to future unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
